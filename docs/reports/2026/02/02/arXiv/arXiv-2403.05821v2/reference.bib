@misc{aws-redshift-llm,
	author = {},
	title = {{L}arge {L}anguage {M}odels for sentiment analysis with {A}mazon {R}edshift {M}{L} ({P}review) | {A}mazon {W}eb {S}ervices --- aws.amazon.com},
	howpublished = {\url{https://aws.amazon.com/blogs/big-data/large-language-models-for-sentiment-analysis-with-amazon-redshift-ml-preview/}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@misc{openaipromptcaching,
    author = {},
    title = {Prompt caching in the API}, 
    note={https://openai.com/index/api-prompt-caching},
    year = 2024,
}
@misc{anthropicpromptcaching,
    author = {},
    title = {Prompt caching with claude},
    howpublished={\url{https://www.anthropic.com/news/prompt-caching}},
    year = 2024,
}

@misc{pyspark,
    author = {},
    title = {PySpark},
    howpublished={ \url{https://www.databricks.com/glossary/pyspark}
    },
    year = {},
}

@misc{gpt4o,
    author = {},
    title = {Hello GPT-4o},
    howpublished = {\url{https://openai.com/index/hello-gpt-4o/}},
    year = {2024},

}

@misc{gemini,
    author = {},
    title = {Context Caching},
    howpublished = {\url{https://ai.google.dev/gemini-api/docs/caching?lang=python}},
    year = {2024},

}




@article{li2023towards,
  title={Towards general text embeddings with multi-stage contrastive learning},
  author={Li, Zehan and Zhang, Xin and Zhang, Yanzhao and Long, Dingkun and Xie, Pengjun and Zhang, Meishan},
  journal={arXiv preprint arXiv:2308.03281},
  year={2023}
}

@misc{promptcache,
      title={Prompt Cache: Modular Attention Reuse for Low-Latency Inference}, 
      author={In Gim and Guojun Chen and Seung-seob Lee and Nikhil Sarda and Anurag Khandelwal and Lin Zhong},
      year={2024},
      eprint={2311.04934},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.04934}, 
}


@misc{google-bigquery-llm,
	author = {},
	title = {{L}{L}{M} with {V}ertex {A}{I} only using {S}{Q}{L} queries in {B}ig{Q}uery | {G}oogle {C}loud {B}log --- cloud.google.com},
	howpublished = {\url{https://cloud.google.com/blog/products/ai-machine-learning/llm-with-vertex-ai-only-using-sql-queries-in-bigquery}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@misc{databricks-ai-functions,
	author = {},
	title = {{A}{I} {F}unctions on {D}atabricks --- docs.databricks.com},
	howpublished = {\url{https://docs.databricks.com/en/large-language-models/ai-functions.html}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@misc{duckdb-tpcds-benchmark,
	author = {},
	title = {{H}ow fast is {D}uck{D}{B} really? | {B}log | {F}ivetran --- fivetran.com},
	howpublished = {\url{https://www.fivetran.com/blog/how-fast-is-duckdb-really}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@inproceedings{duckdb,
author = {Raasveldt, Mark and M\"{u}hleisen, Hannes},
title = {DuckDB: an Embeddable Analytical Database},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3320212},
doi = {10.1145/3299869.3320212},
abstract = {The immense popularity of SQLite shows that there is a need for unobtrusive in-process data management solutions. However, there is no such system yet geared towards analytical workloads. We demonstrate DuckDB, a novel data management system designed to execute analytical SQL queries while embedded in another process. In our demonstration, we pit DuckDB against other data management solutions to showcase its performance in the embedded analytics scenario. DuckDB is available as Open Source software under a permissive license.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {1981–1984},
numpages = {4},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}

@misc{openai-tokenizer,
	author = {OpenAI},
	title = {{O}pen{A}{I}: {L}earn about language model tokenization},
	howpublished = {\url{https://platform.openai.com/tokenizer}},
	year = {},
	note = {[Accessed 29-02-2024]},
}

@misc{openai-pricing,
	author = {OpenAI},
	title = {{P}ricing --- openai.com},
	howpublished = {\url{https://openai.com/pricing}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@misc{llama3, url={https://ai.meta.com/blog/meta-llama-3/}, journal={AI at Meta}, year={2024}, month={Apr}} 

@misc{redshift,
    author = {},
    title={},
    year = {},
    howpubliched={\url{https://docs.aws.amazon.com/redshift/latest/dg/user-defined-functions.html}},
    note={}
}


@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{databricks-aiquery,
    author= {},
    title = {},
    howpublished = {\url{https://docs.databricks.com/en/large-language-models/how-to-ai-query.html}},
    year = {},
    note = {}
}

@misc{llama2-flops,
	author = {},
	title = {{W}hy {G}{P}{T}-3.5 is (mostly) cheaper than {L}lama 2 --- cursor.sh},
	howpublished = {\url{https://cursor.sh/blog/llama-inference}},
	year = {},
	note = {[Accessed 01-03-2024]},
}

@misc{attention-is-all-you-need,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{johnson2019billion,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@inproceedings{spark-sql,
author = {Armbrust, Michael and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J. and Ghodsi, Ali and Zaharia, Matei},
title = {Spark SQL: Relational Data Processing in Spark},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2742797},
doi = {10.1145/2723372.2742797},
abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {1383–1394},
numpages = {12},
keywords = {spark, machine learning, hadoop, databases, data warehouse},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@inproceedings{vllm,
author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
title = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613165},
doi = {10.1145/3600006.3613165},
abstract = {High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2--4\texttimes{} with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. vLLM's source code is publicly available at https://github.com/vllm-project/vllm.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {611–626},
numpages = {16},
location = {<conf-loc>, <city>Koblenz</city>, <country>Germany</country>, </conf-loc>},
series = {SOSP '23}
}

@inproceedings{amazon-product-review-dataset,
author = {He, Ruining and McAuley, Julian},
title = {Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872427.2883037},
doi = {10.1145/2872427.2883037},
abstract = {Building a successful recommender system depends on understanding both the dimensions of people's preferences as well as their dynamics. In certain domains, such as fashion, modeling such preferences can be incredibly difficult, due to the need to simultaneously model the visual appearance of products as well as their evolution over time. The subtle semantics and non-linear dynamics of fashion evolution raise unique challenges especially considering the sparsity and large scale of the underlying datasets. In this paper we build novel models for the One-Class Collaborative Filtering setting, where our goal is to estimate users' fashion-aware personalized ranking functions based on their past feedback. To uncover the complex and evolving visual factors that people consider when evaluating products, our method combines high-level visual features extracted from a deep convolutional neural network, users' past feedback, as well as evolving trends within the community. Experimentally we evaluate our method on two large real-world datasets from Amazon.com, where we show it to outperform state-of-the-art personalized ranking measures, and also use it to visualize the high-level fashion trends across the 11-year span of our dataset.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {507–517},
numpages = {11},
keywords = {fashion evolution, personalized ranking, recommender systems, visual dimensions},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@InProceedings{rotten-tomatoes-movies-dataset,
  author =       {Bo Pang and Lillian Lee},
  title =        {Seeing stars: Exploiting class relationships for sentiment
                  categorization with respect to rating scales},
  booktitle =    {Proceedings of the ACL},
  year =         2005
}

@inproceedings{yu-etal-2018-spider,
    title = "{S}pider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-{SQL} Task",
    author = "Yu, Tao  and
      Zhang, Rui  and
      Yang, Kai  and
      Yasunaga, Michihiro  and
      Wang, Dongxu  and
      Li, Zifan  and
      Ma, James  and
      Li, Irene  and
      Yao, Qingning  and
      Roman, Shanelle  and
      Zhang, Zilin  and
      Radev, Dragomir",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1425",
    doi = "10.18653/v1/D18-1425",
    pages = "3911--3921",
    archivePrefix={arXiv},
    eprint={1809.08887},
    primaryClass={cs.CL},
}

@article{li2024can,
  title={Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls},
  author={Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi and Li, Binhua and Li, Bowen and Wang, Bailin and Qin, Bowen and Geng, Ruiying and Huo, Nan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{ratebeer,
      title={Learning Attitudes and Attributes from Multi-Aspect Reviews}, 
      author={Julian McAuley and Jure Leskovec and Dan Jurafsky},
      year={2012},
      eprint={1210.3926},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1210.3926}, 
}

@misc{Talend, url={https://www.talend.com/resources/what-is-data-redundancy/}, journal={Talend}} 

@misc{catalyst, title={Deep dive into Spark SQL’s catalyst optimizer}, url={https://www.databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html}, journal={Databricks}, author={13, April}} 

@misc{zhang2024benchmarkingtexttosqlcapabilitylarge,
      title={Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation}, 
      author={Bin Zhang and Yuxiao Ye and Guoqing Du and Xiaoru Hu and Zhishuai Li and Sun Yang and Chi Harold Liu and Rui Zhao and Ziyue Li and Hangyu Mao},
      year={2024},
      eprint={2403.02951},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.02951}, 
}

@misc{pdmx,
      title={PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music Processing}, 
      author={Phillip Long and Zachary Novack and Taylor Berg-Kirkpatrick and Julian McAuley},
      year={2024},
      eprint={2409.10831},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2409.10831}, 
}


@misc{gao2023texttosqlempoweredlargelanguage,
      title={Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation}, 
      author={Dawei Gao and Haibin Wang and Yaliang Li and Xiuyu Sun and Yichen Qian and Bolin Ding and Jingren Zhou},
      year={2023},
      eprint={2308.15363},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2308.15363}, 
}

@misc{squad-dataset,
      title={SQuAD: 100,000+ Questions for Machine Comprehension of Text}, 
      author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
      year={2016},
      eprint={1606.05250},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{retrieval-augmented-generation,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{byte-pair-encoding,
      title={A Formal Perspective on Byte-Pair Encoding}, 
      author={Vilém Zouhar and Clara Meister and Juan Luis Gastaldi and Li Du and Tim Vieira and Mrinmaya Sachan and Ryan Cotterell},
      year={2023},
      eprint={2306.16837},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings {orca-continous-batching,
author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
title = {Orca: A Distributed Serving System for {Transformer-Based} Generative Models},
booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
year = {2022},
isbn = {978-1-939133-28-1},
address = {Carlsbad, CA},
pages = {521--538},
url = {https://www.usenix.org/conference/osdi22/presentation/yu},
publisher = {USENIX Association},
month = jul
}

@software{langchain,
author = {Chase, Harrison},
month = oct,
title = {{LangChain}},
url = {https://github.com/langchain-ai/langchain},
year = {2022}
}

@software{llamaindex,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = nov,
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}

@software{faster-transformers,
author = {NVIDIA},
title = {{Faster Transformer}},
url = {https://github.com/NVIDIA/FasterTransformer},
year = {2023}
}

@software{guidance,
author = {Microsoft},
title = {{Guidance}},
url = {https://github.com/guidance-ai/guidance},
year = {2023}
}

@software{aici,
author = {Micrsoft Research},
title = {{Artificial Intelligence Controller Interface (AICI)}},
url = {https://github.com/microsoft/aici},
year = {2023}
}

@software{tgi,
author = {Huggingface},
title = {{Text Generation Inference}},
url = {https://huggingface.co/docs/text-generation-inference/en/index},
year = {2023}
}

@software{trt-llm,
author = {NVIDIA},
title = {{TensorRT LLM}},
url = {https://github.com/NVIDIA/TensorRT-LLM},
year = {2023}
}

@article{lmql,
   title={Prompting Is Programming: A Query Language for Large Language Models},
   volume={7},
   ISSN={2475-1421},
   url={http://dx.doi.org/10.1145/3591300},
   DOI={10.1145/3591300},
   number={PLDI},
   journal={Proceedings of the ACM on Programming Languages},
   publisher={Association for Computing Machinery (ACM)},
   author={Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
   year={2023},
   month=jun, pages={1946–1969} }


@misc{outlines,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{flexgen,
      title={FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU}, 
      author={Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin and Daniel Y. Fu and Zhiqiang Xie and Beidi Chen and Clark Barrett and Joseph E. Gonzalez and Percy Liang and Christopher Ré and Ion Stoica and Ce Zhang},
      year={2023},
      eprint={2303.06865},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hydragen,
      title={Hydragen: High-Throughput LLM Inference with Shared Prefixes}, 
      author={Jordan Juravsky and Bradley Brown and Ryan Ehrlich and Daniel Y. Fu and Christopher Ré and Azalia Mirhoseini},
      year={2024},
      eprint={2402.05099},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sglang,
      title={Efficiently Programming Large Language Models using SGLang}, 
      author={Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Jeff Huang and Chuyue Sun and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
      year={2023},
      eprint={2312.07104},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{velox,
      title={The Missing Piece in Complex Analytics: Low Latency, Scalable Model Management and Serving with Velox}, 
      author={Daniel Crankshaw and Peter Bailis and Joseph E. Gonzalez and Haoyuan Li and Zhao Zhang and Michael J. Franklin and Ali Ghodsi and Michael I. Jordan},
      year={2014},
      eprint={1409.3809},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@misc{madlib,
      title={The MADlib Analytics Library or MAD Skills, the SQL}, 
      author={Joe Hellerstein and Christopher Ré and Florian Schoppmann and Daisy Zhe Wang and Eugene Fratkin and Aleksander Gorajek and Kee Siong Ng and Caleb Welton and Xixuan Feng and Kun Li and Arun Kumar},
      year={2012},
      eprint={1208.4165},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@misc{cascade-inference,
    title = {Cascade Inference: Memory Bandwidth Efficient Shared Prefix Batch Decoding},
    url = {https://flashinfer.ai/2024/02/02/cascade-inference.html},
    author = {Ye, Zihao and Lai, Ruihang and Lu, Bo-Ru and Lin, Chien-Yu and Zheng, Size and Chen, Lequn and Chen, Tianqi and Ceze, Luis},
    month = {February},
    year = {2024}
}

@misc{spotserve,
      title={SpotServe: Serving Generative Large Language Models on Preemptible Instances}, 
      author={Xupeng Miao and Chunan Shi and Jiangfei Duan and Xiaoli Xi and Dahua Lin and Bin Cui and Zhihao Jia},
      year={2023},
      eprint={2311.15566},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{semdedup,
      title={SemDeDup: Data-efficient learning at web-scale through semantic deduplication}, 
      author={Amro Abbas and Kushal Tirumala and Dániel Simig and Surya Ganguli and Ari S. Morcos},
      year={2023},
      eprint={2303.09540},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{flash-attention,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{ralf-feature-store,
author = {Wooders, Sarah and Mo, Xiangxi and Narang, Amit and Lin, Kevin and Stoica, Ion and Hellerstein, Joseph M. and Crooks, Natacha and Gonzalez, Joseph E.},
title = {RALF: Accuracy-Aware Scheduling for Feature Store Maintenance},
year = {2023},
issue_date = {November 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3632093.3632116},
doi = {10.14778/3632093.3632116},
abstract = {Feature stores (also sometimes referred to as embedding stores) are becoming ubiquitous in model serving systems: downstream applications query these stores for auxiliary inputs at inference-time. Stored features are derived by featurizing rapidly changing base data sources. Featurization can be costly prohibitively expensive to trigger on every data update, particularly for features that are vector embeddings computed by a model. Yet, existing systems naively apply a one-size-fits-all policy as to when/how to update these features, and do not consider query access patterns or impacts on prediction accuracy. This paper introduces RALF, which orchestrates feature updates by leveraging downstream error feedback to minimize feature store regret, a metric for how much featurization degrades downstream accuracy. We evaluate with representative feature store workloads, anomaly detection and recommendation, using real-world datasets. We run system experiments with a 275,077 key anomaly detection workload on 800 cores to show up to a 32.7\% reduction in prediction error or up to 1.6X compute cost reduction with accuracy-aware scheduling.},
journal = {Proc. VLDB Endow.},
month = {nov},
pages = {563–576},
numpages = {14}
}

@article{noscope,
author = {Kang, Daniel and Emmons, John and Abuzaid, Firas and Bailis, Peter and Zaharia, Matei},
title = {NoScope: optimizing neural network queries over video at scale},
year = {2017},
issue_date = {August 2017},
publisher = {VLDB Endowment},
volume = {10},
number = {11},
issn = {2150-8097},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1586–1597},
numpages = {12}
}

@article{blazeit,
author = {Kang, Daniel and Bailis, Peter and Zaharia, Matei},
title = {BlazeIt: optimizing declarative aggregation and limit queries for neural network-based video analytics},
year = {2019},
issue_date = {December 2019},
publisher = {VLDB Endowment},
volume = {13},
number = {4},
issn = {2150-8097},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {533–546},
numpages = {14}
}

@inproceedings{zaharia2012resilient,
  title={Resilient distributed datasets: A $\{$Fault-Tolerant$\}$ abstraction for $\{$In-Memory$\}$ cluster computing},
  author={Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur and Ma, Justin and McCauly, Murphy and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
  booktitle={9th USENIX symposium on networked systems design and implementation (NSDI 12)},
  pages={15--28},
  year={2012}
}

@inproceedings{prob-pred,
author = {Lu, Yao and Chowdhery, Aakanksha and Kandula, Srikanth and Chaudhuri, Surajit},
title = {Accelerating Machine Learning Inference with Probabilistic Predicates},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
pages = {1493–1508},
numpages = {16},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@inproceedings{gdsf,
author = {Cherkasova, Ludmila and Ciardo, Gianfranco},
title = {Role of Aging, Frequency, and Size in Web Cache Replacement Policies},
year = {2001},
isbn = {3540422935},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 9th International Conference on High-Performance Computing and Networking},
pages = {114–123},
numpages = {10},
series = {HPCN Europe 2001}
}

@misc{fever,
      title={FEVER: a large-scale dataset for Fact Extraction and VERification}, 
      author={James Thorne and Andreas Vlachos and Christos Christodoulopoulos and Arpit Mittal},
      year={2018},
      eprint={1803.05355},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1803.05355}, 
}

@article{deltalake,
  title={Delta lake: high-performance ACID table storage over cloud object stores},
  author={Armbrust, Michael and Das, Tathagata and Sun, Liwen and Yavuz, Burak and Zhu, Shixiong and Murthy, Mukul and Torres, Joseph and van Hovell, Herman and Ionescu, Adrian and {\L}uszczak, Alicja and others},
  journal={Proceedings of the VLDB Endowment},
  volume={13},
  number={12},
  pages={3411--3424},
  year={2020},
  publisher={VLDB Endowment}
}
@article{mdc,
  title={Model-based multidimensional clustering of categorical data},
  author={Chen, Tao and Zhang, Nevin L and Liu, Tengfei and Poon, Kin Man and Wang, Yi},
  journal={Artificial Intelligence},
  volume={176},
  number={1},
  pages={2246--2269},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{craking,
  title={Database Cracking.},
  author={Idreos, Stratos and Kersten, Martin L and Manegold, Stefan and others},
  booktitle={CIDR},
  volume={7},
  pages={68--78},
  year={2007}
}

@inproceedings{correlation,
  title={CORDS: Automatic discovery of correlations and soft functional dependencies},
  author={Ilyas, Ihab F and Markl, Volker and Haas, Peter and Brown, Paul and Aboulnaga, Ashraf},
  booktitle={Proceedings of the 2004 ACM SIGMOD international conference on Management of data},
  pages={647--658},
  year={2004}
}

@article{multirelation,
  title={Multi-relational data mining: an introduction},
  author={D{\v{z}}eroski, Sa{\v{s}}o},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={5},
  number={1},
  pages={1--16},
  year={2003},
  publisher={ACM New York, NY, USA}
}

@article{lemire2011reordering,
  title={Reordering columns for smaller indexes},
  author={Lemire, Daniel and Kaser, Owen},
  journal={Information Sciences},
  volume={181},
  number={12},
  pages={2550--2570},
  year={2011},
  publisher={Elsevier}
}

@incollection{stonebraker2018c,
  title={C-store: a column-oriented DBMS},
  author={Stonebraker, Mike and Abadi, Daniel J and Batkin, Adam and Chen, Xuedong and Cherniack, Mitch and Ferreira, Miguel and Lau, Edmond and Lin, Amerson and Madden, Sam and O'Neil, Elizabeth and others},
  booktitle={Making Databases Work: the Pragmatic Wisdom of Michael Stonebraker},
  pages={491--518},
  year={2018}
}

@incollection{bootstrapping,
  author    = {Ran R. Wilcox},
  title     = {Bootstrap Confidence Interval},
  booktitle = {Applying Contemporary Statistical Techniques},
  publisher = {Academic Press},
  year      = {2003},
}

@article{systemml,
author = {Boehm, Matthias and Dusenberry, Michael W. and Erikkson, Deron and Evfimievski, Alexandre V. and Manshadi, Faraz Makar and Pansare, Niketan and Reinwald, Berthold and Reiss, Frederick R. and Sen, Prithviraj and Surve, Arvind C. and Tatikonda Shirish},
title = {SystemML: Declarative Machine Learning on Spark},
year = {2016},
publisher = {VLDB Endowment},
volume = {9},
number = {13},
issn = {2150-8097},
}

@misc{sparkmllib,
      title={MLlib: Machine Learning in Apache Spark}, 
      author={Xiangrui Meng and Joseph Bradley and Burak Yavuz and Evan Sparks and Shivaram Venkataraman and Davies Liu and Jeremy Freeman and DB Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and Michael J. Franklin and Reza Zadeh and Matei Zaharia and Ameet Talwalkar},
      year={2015},
      eprint={1505.06807},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1505.06807}, 
}

@misc{lotus,
      title={LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data}, 
      author={Liana Patel and Siddharth Jha and Carlos Guestrin and Matei Zaharia},
      year={2024},
      eprint={2407.11418},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2407.11418}, 
}



