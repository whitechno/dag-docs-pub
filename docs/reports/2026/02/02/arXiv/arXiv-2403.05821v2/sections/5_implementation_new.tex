\vspace{-0.5em}

\section{Implementation}
We implement our algorithms in approximately 1.3K lines of Python code and evaluate them with PySpark~\cite{spark-sql}, which is backed by Apache Spark~\cite{zaharia2012resilient} -- a widely adopted large-scale data processing engine in industry.
The \textit{LLM operator} implements the actual
LLM inference by calling a configurable LLM endpoint. We implement this function as a UDF in PySpark. It takes in a system prompt, a query prompt, and a single row of data as input (Appendix~\ref{appendix:prompts}). 
The row and field orders are input based on the ordering returned by the reordering function. 
The operator is also responsible for \textit{prompt construction}. Specifically, it converts the user-provided question and the table row values into a prompt that an LLM can parse. We use JSON formatting to encode row values to indicate the relationship between field names and values to the LLM. 
%, ensuring the model correctly interprets the inputs provided. % \shu{wordings are weird with LLM UDFs} The UDF implements The first part of every prompt is the \textit{system prompt} containing instructions for the LLM. In the \textit{user prompt}, the question is provided as well as a JSON encoding of the field values for a particular row.

% \asim{can maybe cut this example? or move to appendix if we are doing one}
% For example, given the following query \amog{move this into a Figure instead of having it in the text}:
% \begin{minted}[fontsize=\small]{sql}
% SELECT LLM("QUESTION") FROM my_table
% \end{minted}



% The final prompt is constructed like so:

% System prompt: 
% \begin{minted}[fontsize=\small]{text}
% You are a helpful data analyst. You will receive JSON data containing various fields and their corresponding values, representing different attributes. Use these fields to provide an answer to the user query. The user query will indicate which fields to use for your response. Your response should contain only the answer and no additional formatting.
% \end{minted}

% User prompt: 
% \begin{minted}[fontsize=\small]{text}
% Answer the below query:
% QUESTION
% given the following data:
% {col_name1: col_value1, col_name2: col_value2, ...}
% \end{minted}
% Furthermore, UDFs can be added to support LLM invocation inside queries. 
% which we leverage for our experiments. 
%\asim{do we need to update this text to be more batch analytics focused?}
% \shu{remove or just add more, say we have a python package (?) or this is generally applicable to all dataframes etc. }
% 1. ReorderFn: applies the reordering algorithms as described in the previous section.

% 2. LLMFn: performs LLM inference on each row of the table.
% \textbf{Reordering Algorithm} We implement the \greedy algorithm as described in Section 3.3. Our implementation takes the entire table as input and possibly any precomputed statistics about each field, such as cardinality and average length. It also optionally takes in any known functional dependencies. After applying \greedy, we return a list of indexes indicating the row and field orders.
% 1. RowOrder: A single integer containing the global ordering of a particular row after MGH is applied.
% 2. ColOrder: A sequence of integers which represents the column ordering for a particular row,
% After the algorithm is applied, the entire table is sorted by the RowOrder column.
% \shu{change the notion of UDF to operator, write a SQL example or dataframe example here?}